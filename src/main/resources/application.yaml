app:
  ai:
    provider: ollama  # choose between ollama, openai, azure

spring:
  application:
    name: spring-ai-intro
  ai:
    chat:
      client:
        enabled: false # disable auto configuration of ChatClient, there are multiple LLM implementations
    ollama:
        base-url: http://localhost:11434/
        chat:
          options:
            model: llama3.2
        embedding:
          options:
            model: nomic-embed-text
    openai:
        base-url: https://api.openai.com/
        api-key: ${OPENAI_API_KEY}
        chat:
          options:
            model: gpt-4o
        embedding:
          options:
            model: text-embedding-3-small

